{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/book-resources/blob/main/chapter1/resnet_identity_network_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBgedt4FXXvC",
        "outputId": "cf914533-4398-4bed-b1bb-23778d6533c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.7/dist-packages (1.4.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics torch-summary\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7rQ6rusF-8Mi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bugkPe_084re",
        "outputId": "51a428f1-fd4f-4f37-abfc-34551ffeb42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HmZ0P89ZM6Dt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e49ba60-2c3f-4a5f-880b-e70f5998c4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 75 5842k   75 4416k    0     0  37.1M      0 --:--:-- --:--:-- --:--:-- 36.8M\r100 5842k  100 5842k    0     0  47.5M      0 --:--:-- --:--:-- --:--:-- 47.1M\n",
            "Archive:  smartreply.zip\n",
            "replace smartreply.tflite? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: smartreply.tflite       \n",
            "  inflating: backoff_response.txt    \n"
          ]
        }
      ],
      "source": [
        "!pip install -q netron\n",
        "!curl --output smartreply.zip https://storage.googleapis.com/download.tensorflow.org/models/tflite/smartreply_1.0_2017_11_01.zip\n",
        "!unzip smartreply.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TjZsv6riVOP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a50a02-4a36-4fb6-aad8-b0eee8b92658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZQ3wWIEeAtO8"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super().__init__()\n",
        "    self.stride = stride\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.stride > 1:\n",
        "      identity = self.downsample(x)\n",
        "      # assert identity.shape == out.shape\n",
        "\n",
        "    out = out + identity\n",
        "    out = self.relu(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "CjpQMRdoFhMh"
      },
      "outputs": [],
      "source": [
        "height = 32\n",
        "width= 32\n",
        "in_channels = 16\n",
        "fake_input = torch.rand(1,3,height,width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DqUka0S-Fbk3"
      },
      "outputs": [],
      "source": [
        "# block = ResidualBlock(3,in_channels,1)\n",
        "# out = block(fake_input)\n",
        "# assert out.shape == (1,in_channels,height,width), f\"Unexpented shape of {out.shape}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "v-ZqCOF4E8Wn"
      },
      "outputs": [],
      "source": [
        "# fake_input = torch.rand(1,16,height,width)\n",
        "# block = ResidualBlock(16,16,2)\n",
        "# out = block(fake_input)\n",
        "# assert out.shape == (1,in_channels,height//2,width//2), f\"Unexpented shape of {out.shape}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wtYV_6sy_Twg"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1, stride=1)\n",
        "    self.layer1 = self.make_layer(16, out_channels=16, stride=1, n_layers=n)\n",
        "    self.layer2 = self.make_layer(16, out_channels=32, stride=2, n_layers=n)\n",
        "    self.layer3 = self.make_layer(32, out_channels=64, stride=2, n_layers=n)\n",
        "    self.global_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.linear = nn.Linear(64, 10)\n",
        "\n",
        "  def make_layer(self, in_channels, out_channels, stride, n_layers):\n",
        "    layer = []\n",
        "    layer.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "    for i in range(n_layers-1):\n",
        "      layer.append(ResidualBlock(out_channels, out_channels, 1))\n",
        "    return nn.Sequential(*layer)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.global_pooling(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.linear(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0rlU3JYGJFo",
        "outputId": "5c37bd57-4598-4c1c-d830-ade10ee14e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Conv2d: 1-1                            [-1, 16, 32, 32]          448\n",
            "├─Sequential: 1-2                        [-1, 16, 32, 32]          --\n",
            "|    └─ResidualBlock: 2-1                [-1, 16, 32, 32]          --\n",
            "|    |    └─Conv2d: 3-1                  [-1, 16, 32, 32]          2,320\n",
            "|    |    └─BatchNorm2d: 3-2             [-1, 16, 32, 32]          32\n",
            "|    |    └─ReLU: 3-3                    [-1, 16, 32, 32]          --\n",
            "|    |    └─Conv2d: 3-4                  [-1, 16, 32, 32]          2,320\n",
            "|    |    └─BatchNorm2d: 3-5             [-1, 16, 32, 32]          32\n",
            "|    |    └─ReLU: 3-6                    [-1, 16, 32, 32]          --\n",
            "├─Sequential: 1-3                        [-1, 32, 16, 16]          --\n",
            "|    └─ResidualBlock: 2-2                [-1, 32, 16, 16]          --\n",
            "|    |    └─Conv2d: 3-7                  [-1, 32, 16, 16]          4,640\n",
            "|    |    └─BatchNorm2d: 3-8             [-1, 32, 16, 16]          64\n",
            "|    |    └─ReLU: 3-9                    [-1, 32, 16, 16]          --\n",
            "|    |    └─Conv2d: 3-10                 [-1, 32, 16, 16]          9,248\n",
            "|    |    └─BatchNorm2d: 3-11            [-1, 32, 16, 16]          64\n",
            "|    |    └─Conv2d: 3-12                 [-1, 32, 16, 16]          544\n",
            "|    |    └─ReLU: 3-13                   [-1, 32, 16, 16]          --\n",
            "├─Sequential: 1-4                        [-1, 64, 8, 8]            --\n",
            "|    └─ResidualBlock: 2-3                [-1, 64, 8, 8]            --\n",
            "|    |    └─Conv2d: 3-14                 [-1, 64, 8, 8]            18,496\n",
            "|    |    └─BatchNorm2d: 3-15            [-1, 64, 8, 8]            128\n",
            "|    |    └─ReLU: 3-16                   [-1, 64, 8, 8]            --\n",
            "|    |    └─Conv2d: 3-17                 [-1, 64, 8, 8]            36,928\n",
            "|    |    └─BatchNorm2d: 3-18            [-1, 64, 8, 8]            128\n",
            "|    |    └─Conv2d: 3-19                 [-1, 64, 8, 8]            2,112\n",
            "|    |    └─ReLU: 3-20                   [-1, 64, 8, 8]            --\n",
            "├─AdaptiveAvgPool2d: 1-5                 [-1, 64, 1, 1]            --\n",
            "├─Linear: 1-6                            [-1, 10]                  650\n",
            "==========================================================================================\n",
            "Total params: 78,154\n",
            "Trainable params: 78,154\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 12.66\n",
            "==========================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.09\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 1.40\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Conv2d: 1-1                            [-1, 16, 32, 32]          448\n",
              "├─Sequential: 1-2                        [-1, 16, 32, 32]          --\n",
              "|    └─ResidualBlock: 2-1                [-1, 16, 32, 32]          --\n",
              "|    |    └─Conv2d: 3-1                  [-1, 16, 32, 32]          2,320\n",
              "|    |    └─BatchNorm2d: 3-2             [-1, 16, 32, 32]          32\n",
              "|    |    └─ReLU: 3-3                    [-1, 16, 32, 32]          --\n",
              "|    |    └─Conv2d: 3-4                  [-1, 16, 32, 32]          2,320\n",
              "|    |    └─BatchNorm2d: 3-5             [-1, 16, 32, 32]          32\n",
              "|    |    └─ReLU: 3-6                    [-1, 16, 32, 32]          --\n",
              "├─Sequential: 1-3                        [-1, 32, 16, 16]          --\n",
              "|    └─ResidualBlock: 2-2                [-1, 32, 16, 16]          --\n",
              "|    |    └─Conv2d: 3-7                  [-1, 32, 16, 16]          4,640\n",
              "|    |    └─BatchNorm2d: 3-8             [-1, 32, 16, 16]          64\n",
              "|    |    └─ReLU: 3-9                    [-1, 32, 16, 16]          --\n",
              "|    |    └─Conv2d: 3-10                 [-1, 32, 16, 16]          9,248\n",
              "|    |    └─BatchNorm2d: 3-11            [-1, 32, 16, 16]          64\n",
              "|    |    └─Conv2d: 3-12                 [-1, 32, 16, 16]          544\n",
              "|    |    └─ReLU: 3-13                   [-1, 32, 16, 16]          --\n",
              "├─Sequential: 1-4                        [-1, 64, 8, 8]            --\n",
              "|    └─ResidualBlock: 2-3                [-1, 64, 8, 8]            --\n",
              "|    |    └─Conv2d: 3-14                 [-1, 64, 8, 8]            18,496\n",
              "|    |    └─BatchNorm2d: 3-15            [-1, 64, 8, 8]            128\n",
              "|    |    └─ReLU: 3-16                   [-1, 64, 8, 8]            --\n",
              "|    |    └─Conv2d: 3-17                 [-1, 64, 8, 8]            36,928\n",
              "|    |    └─BatchNorm2d: 3-18            [-1, 64, 8, 8]            128\n",
              "|    |    └─Conv2d: 3-19                 [-1, 64, 8, 8]            2,112\n",
              "|    |    └─ReLU: 3-20                   [-1, 64, 8, 8]            --\n",
              "├─AdaptiveAvgPool2d: 1-5                 [-1, 64, 1, 1]            --\n",
              "├─Linear: 1-6                            [-1, 10]                  650\n",
              "==========================================================================================\n",
              "Total params: 78,154\n",
              "Trainable params: 78,154\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 12.66\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 1.09\n",
              "Params size (MB): 0.30\n",
              "Estimated Total Size (MB): 1.40\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model = ResNet(n=1)\n",
        "model = model.to(device)\n",
        "summary(model, (3,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KmoFGt4MGIZt"
      },
      "outputs": [],
      "source": [
        "# convert to onnx format\n",
        "model_path = \"./plainnet.pth\"\n",
        "_ = torch.onnx.export(model.to(device), fake_input.to(device), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "W8mu0_PbNOhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "7c62cddf-e84c-4187-d23d-786bdc0f95b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(20065, \"/\", \"100%\", \"800\", false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start(model_path, port, browse=False)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i7pg6dXpA5Lm"
      },
      "outputs": [],
      "source": [
        "## training parameters\n",
        "weight_decay = 0.0001\n",
        "momentum = 0.9\n",
        "batch_size = 128\n",
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P3J_n6s8NtDe"
      },
      "outputs": [],
      "source": [
        "## We follow the simple data augmen-tation in [24] for training: 4 pixels\n",
        "## are padded on each side, and  a  32×32  crop  is  randomly  sampled  from  \n",
        "## the  padded image or its horizontal flip.  For testing, we only evaluate the\n",
        "## single view of the original 32×32 image\n",
        "\n",
        "train_augmentations = transforms.Compose([\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.RandomCrop(size=32, padding=4, fill=0, padding_mode='constant'),\n",
        "     transforms.ToTensor()])\n",
        "\n",
        "test_augmentations = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmvqrp6E_DdI",
        "outputId": "89b0cca7-80c3-4203-ec06-3aaabf44ff40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.CIFAR10(root=\".\", train = True, download=True, transform=train_augmentations)\n",
        "test_dataset = datasets.CIFAR10(root=\".\", train=False, transform=test_augmentations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wtZdHuE_Q2qK"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                           shuffle=True, sampler=None, drop_last=True, \n",
        "                                           num_workers=0)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
        "                                           shuffle=False, sampler=None, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrBFjihp84rl",
        "outputId": "5145d73d-e166-43e4-e1d4-4619ed2cd42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train for 164 epochs.\n",
            "Learning rate decreases at epochs 82 and 123\n"
          ]
        }
      ],
      "source": [
        "total_epochs = round(64_000 / len(train_loader))\n",
        "lr_step1 = round(32_000 / len(train_loader))\n",
        "lr_step2 = round(48_000 / len(train_loader))\n",
        "print(f\"Train for {total_epochs} epochs.\")\n",
        "print(f\"Learning rate decreases at epochs {lr_step1} and {lr_step2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wEIuYjG984rm"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, epochs, optimizer, lr_scheduler, device):\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        self.accuracy = Accuracy(num_classes=10).to(device)\n",
        "        self.training_error = []\n",
        "        self.testing_error = []\n",
        "        self.loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "        \n",
        "    def fit(self, model, train_loader, test_loader):\n",
        "        iter = 0\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "            train_error = 0\n",
        "\n",
        "            model.train()\n",
        "            for x_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "\n",
        "                logits = model(x_batch)\n",
        "                loss = self.loss_fn(logits, y_batch)\n",
        "                \n",
        "                train_acc = 100 * self.accuracy(logits, y_batch)\n",
        "                train_error += (100 - train_acc)\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # if iter % 10 == 0:\n",
        "                #   print(f\"Epoch: {epoch}\\tLoss: {loss}\")\n",
        "\n",
        "                iter += 1\n",
        "\n",
        "            self.lr_scheduler.step()\n",
        "            train_error /= len(train_loader)\n",
        "            self.training_error.append(train_error.item())\n",
        "\n",
        "            model.eval()\n",
        "            test_error = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for x_batch, y_batch in test_loader:\n",
        "                    x_batch = x_batch.to(device)\n",
        "                    y_batch = y_batch.to(device)\n",
        "                    logits = model(x_batch)\n",
        "\n",
        "                    test_acc = 100 * self.accuracy(logits, y_batch)\n",
        "                    test_error += (100 - test_acc)\n",
        "\n",
        "                test_error /= len(test_loader)\n",
        "                self.testing_error.append(test_error.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the plain CNN for n=3"
      ],
      "metadata": {
        "id": "Gj7Gqmhk9YRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet20 = ResNet(n=3)\n",
        "resnet20 = resnet20.to(device)"
      ],
      "metadata": {
        "id": "rufzW7Jl9dWs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dc-nsZehUoir"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(resnet20.parameters(), lr=learning_rate, \n",
        "                            weight_decay=weight_decay, momentum=momentum)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_step1, lr_step2], gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RELAXzj4RGCu"
      },
      "outputs": [],
      "source": [
        "trainer20 = Trainer(total_epochs, optimizer, scheduler, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "kr3w3wZV84rn",
        "outputId": "e4ce9dca-dda4-4824-f38f-0a5c3482d07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/164 [11:19<30:46:51, 679.83s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-31e257f02ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplainet20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-73280fd4ff69>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7358c4591385>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2cbcadf19f45>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m     )\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer20.fit(resnet20, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the plain CNN for n=5"
      ],
      "metadata": {
        "id": "Uiryjn4x870a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet32 = ResNet(n=5)\n",
        "resnet32 = resnet32.to(device)"
      ],
      "metadata": {
        "id": "WItRsqEb8_WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(resnet32.parameters(), lr=learning_rate, \n",
        "                            weight_decay=weight_decay, momentum=momentum)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_step1, lr_step2], gamma=0.1)"
      ],
      "metadata": {
        "id": "8ZDLtYsD9BVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer32 = Trainer(total_epochs, optimizer, scheduler, device)"
      ],
      "metadata": {
        "id": "oxa7Q4Hk9PdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer32.fit(resnet32, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "qX1MtSIB9Pik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the plain CNN for n=7"
      ],
      "metadata": {
        "id": "KU5UQsHyfo6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet44 = ResNet(n=7)\n",
        "resnet44 = resnet44.to(device)"
      ],
      "metadata": {
        "id": "y39g8udtfoFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(resnet44.parameters(), lr=learning_rate, \n",
        "                            weight_decay=weight_decay, momentum=momentum)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[lr_step1, lr_step2], gamma=0.1)"
      ],
      "metadata": {
        "id": "quXApsYvf1yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer44 = Trainer(total_epochs, optimizer, scheduler, device)"
      ],
      "metadata": {
        "id": "ULxf4uILf28_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer44.fit(resnet44, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "JNBdPkv6f3BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing and Visualizing training and test errors"
      ],
      "metadata": {
        "id": "pwyEJr5a9ppl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtvnZmuQc3Ac"
      },
      "outputs": [],
      "source": [
        "def add_lines(ax, train_error, test_error, color, label):\n",
        "  line, = ax.plot(train_error, label=label, color=color, linestyle='--')\n",
        "  _, = ax.plot(test_error, color=color, linewidth=2)\n",
        "  return line\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "line1 = add_lines(ax, trainer20.training_error, trainer20.testing_error, color=\"red\", label=\"plain-20\")\n",
        "line2 = add_lines(ax, trainer32.training_error, trainer32.testing_error, color=\"blue\", label=\"plain-32\")\n",
        "line3 = add_lines(ax, trainer44.training_error, trainer44.testing_error, color=\"green\", label=\"plain-44\")\n",
        "\n",
        "# Create a legend for the first line.\n",
        "legend = ax.legend(handles=[line1, line2, line3], loc='upper right')\n",
        "\n",
        "# Add the legend manually to the Axes.\n",
        "ax.add_artist(legend)\n",
        "ax.set_xlabel('epochs')\n",
        "ax.set_ylabel('error (%)')\n",
        "\n",
        "plt.savefig(\"plain-nets-experiment.svg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "k3h_w__L_Zkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"epoch\": range(len(trainer20.training_error)),\n",
        "              \"plain-20-train-err\": trainer20.training_error,\n",
        "              \"plain-20-test-err\": trainer20.testing_error,\n",
        "              \"plain-32-train-err\": trainer32.training_error,\n",
        "              \"plain-32-test-err\": trainer32.testing_error,\n",
        "              \"plain-44-train-err\": trainer44.training_error,\n",
        "              \"plain-44-test-err\": trainer44.testing_error})\n",
        "df.to_csv('res_net_experiment.csv', index=False)"
      ],
      "metadata": {
        "id": "i9mJrIANxdtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "IRcPbbF1xm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2PEkEAf0Odl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}